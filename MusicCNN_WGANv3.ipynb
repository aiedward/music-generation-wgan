{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import librosa\n",
    "from librosa.display import specshow\n",
    "from librosa.display import waveplot\n",
    "\n",
    "import IPython.display as ipyd\n",
    "\n",
    "from scipy.signal import stft as sp_stft\n",
    "from scipy.signal import istft as sp_istft\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "import time\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers import Lambda, ZeroPadding2D, Embedding, Multiply\n",
    "from keras.layers import Conv2D, Concatenate\n",
    "from keras.layers import Conv2DTranspose as Conv2DT\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import LeakyReLU, Activation, ELU\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.initializers import RandomNormal\n",
    "from keras import regularizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02)\n",
    "l2_reg = regularizers.l2(1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is modified from https://github.com/tjwei/GANotebooks/blob/master/wgan-keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_DCGAN_D(n_freq, n_time, n_c, n_df, n_class=None):\n",
    "    \n",
    "    # move more along time axis\n",
    "    #if n_freq != n_time:\n",
    "    #    ks = (4, 8)\n",
    "    #    strides = (2, 4)\n",
    "    #else:\n",
    "    #    ks = (4, 4)\n",
    "    #    strides = (2, 2)\n",
    "    ks = (4, 4)\n",
    "    strides = (2, 2)\n",
    "    \n",
    "    inputs =Input(shape=(n_freq, n_time, n_c))\n",
    "    \n",
    "    # XXX: Why not use bias ? \n",
    "    x = Conv2D(filters=n_df, kernel_size=ks, strides=strides, kernel_regularizer=l2_reg,\n",
    "            kernel_initializer=conv_init, padding='same', use_bias=False, \n",
    "            name='initial.conv.{0}-{1}'.format(n_c, n_df))(inputs)\n",
    "    x = LeakyReLU(alpha=0.2, \n",
    "           name='initial.relu.{0}'.format(n_df))(x)\n",
    "    \n",
    "    c_nfreq, c_ntime = n_freq // strides[0], n_time // strides[1]\n",
    "    c_ndf = n_df\n",
    "    \n",
    "    # Extra layer conv along time\n",
    "    n_extra = 0\n",
    "    while c_ntime > c_nfreq:\n",
    "        x = Conv2D(filters=n_df, kernel_size=(1, 3), strides=(1, 2), kernel_regularizer=l2_reg,\n",
    "                kernel_initializer=conv_init, padding='same', use_bias=False, \n",
    "                name='extra.{0}-{1}.conv'.format(n_extra, c_ntime))(x)\n",
    "        #x = BatchNorm(gamma_initializer=gamma_init, epsilon=1.01e-5, momentum=0.9,\n",
    "        #        name='pyramid.{0}.bn'.format(n_op_feats))(x, training=1)\n",
    "        x = LeakyReLU(alpha=0.2, \n",
    "               name='extra.{0}-{1}.relu'.format(n_extra, c_ntime))(x)\n",
    "        n_extra += 1\n",
    "        c_ntime = c_ntime // 2\n",
    "    \n",
    "    # Pyramid Conv\n",
    "    while c_nfreq > 4:\n",
    "        n_in_feats = c_ndf\n",
    "        n_op_feats = c_ndf * 2\n",
    "        \n",
    "        x = Conv2D(filters=n_op_feats, kernel_size=ks, strides=strides, kernel_regularizer=l2_reg,\n",
    "                kernel_initializer=conv_init, padding='same', use_bias=False, \n",
    "                name='pyramid.{0}-{1}.conv'.format(n_in_feats, n_op_feats))(x)\n",
    "        #x = BatchNorm(gamma_initializer=gamma_init, epsilon=1.01e-5, momentum=0.9,\n",
    "        #        name='pyramid.{0}.bn'.format(n_op_feats))(x, training=1)\n",
    "        x = LeakyReLU(alpha=0.2, \n",
    "               name='pyramid.{0}.relu'.format(n_op_feats))(x)\n",
    "                   \n",
    "        c_nfreq, c_ntime = c_nfreq // strides[0], c_ntime // strides[1]\n",
    "        c_ndf = c_ndf * 2\n",
    "\n",
    "    output_fake = Conv2D(filters=1, kernel_size=(c_nfreq, c_ntime), strides=1, use_bias=False,  \n",
    "            kernel_initializer=conv_init, kernel_regularizer=l2_reg,\n",
    "            name='final.{0}-{1}.conv'.format(c_ndf, 1))(x)\n",
    "    output_fake = Flatten()(output_fake)\n",
    "    \n",
    "#     # ACGAN improvement\n",
    "#     if n_class is not None:\n",
    "#         output_class = Conv2D(filters=n_class, kernel_size=(c_nfreq, c_ntime), strides=1, use_bias=False, \n",
    "#                             kernel_initializer=conv_init, kernel_regularizer=l2_reg,  \n",
    "#                             name='final.{0}-{1}.conv'.format(c_ndf, n_class))(x)\n",
    "#         output_class = Flatten()(output_class)\n",
    "#         output_class = Activation('softmax')(output_class)\n",
    "#         return Model(inputs=[inputs], outputs=[output_fake, output_class], name='discriminator')\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[output_fake], name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_DCGAN_G(n_z, n_gf, n_freq, n_time, n_c, n_class=None):\n",
    "        \n",
    "    # move more along time axis\n",
    "#     if n_freq != n_time:\n",
    "#         ks = (4, 8)\n",
    "#         strides = (2, 4)\n",
    "#     else:\n",
    "#         ks = (4, 4)\n",
    "#         strides = (2, 2)\n",
    "    ks = (4, 4)\n",
    "    strides = (2, 2)\n",
    "    \n",
    "    # compute generator first layer channel\n",
    "    c_ngf = n_gf // 2\n",
    "    c_nfreq, c_ntime = n_freq, n_time\n",
    "    \n",
    "    while c_nfreq > 4:\n",
    "        c_ngf = c_ngf * 2\n",
    "        c_nfreq = c_nfreq // strides[0]\n",
    "        c_ntime = c_ntime // strides[1]\n",
    "        \n",
    "    # first back dconv\n",
    "    input_z = Input(shape=(n_z, ))\n",
    "    \n",
    "#     # ACGAN improvement\n",
    "#     if n_class is not None:\n",
    "#         input_class = Input(shape=(1, ), dtype='int32')\n",
    "#         embedding = Embedding(input_dim=n_class, output_dim=n_z, embeddings_initializer='glorot_uniform',\n",
    "#                 name='initial.{0}.embed'.format(n_class))(input_class)\n",
    "#         embedding = Flatten()(embedding)\n",
    "#         x = Multiply()([input_z, embedding])\n",
    "#         x = Reshape((1, 1 , n_z))(x)\n",
    "#     else:\n",
    "#         x = Reshape((1, 1 , n_z))(input_z)\n",
    "    x = Reshape((1, 1 , n_z))(input_z)\n",
    "    \n",
    "    x = Conv2DT(filters=c_ngf, kernel_size=(c_nfreq, c_nfreq), strides=1, use_bias=False,\n",
    "            kernel_initializer=conv_init, #kernel_regularizer=l2_reg, #padding='samker \n",
    "            name = 'initial.{0}-{1}.convt'.format(n_z, c_ngf))(x)\n",
    "    x = BatchNorm(epsilon=1.01e-5, momentum=0.9,\n",
    "            name = 'initial.{0}.bn'.format(c_ngf))(x, training=1)\n",
    "    x = Activation(\"relu\", \n",
    "            name='initial.{0}.relu'.format(c_ngf))(x)\n",
    "    \n",
    "    while c_nfreq < n_freq // 2:\n",
    "        n_in_feats = c_ngf\n",
    "        n_op_feats = c_ngf // 2\n",
    "        \n",
    "        x = Conv2DT(filters=n_op_feats, kernel_size=ks, strides=strides, use_bias=False,\n",
    "                kernel_initializer=conv_init, padding='same', #kernel_regularizer=l2_reg,\n",
    "                name='pyramid.{0}-{1}.convt'.format(n_in_feats, n_op_feats))(x)\n",
    "        x = BatchNorm(gamma_initializer=gamma_init, epsilon=1.01e-5, momentum=0.9,\n",
    "                name='pyramid.{0}.bn'.format(n_op_feats))(x, training=1)\n",
    "        x = Activation(\"relu\",\n",
    "               name = 'pyramid.{0}.relu'.format(n_op_feats))(x)\n",
    "        c_nfreq = c_nfreq * strides[0]\n",
    "        c_ngf = c_ngf // 2\n",
    "        \n",
    "    # extra layer conv along time\n",
    "    n_extra = 0\n",
    "    while n_time > c_ntime:\n",
    "        x = Conv2DT(filters=c_ngf, kernel_size=(1, 3), strides=(1 ,2), use_bias=False,\n",
    "                kernel_initializer=conv_init, padding='same', #kernel_regularizer=l2_reg,\n",
    "                name='extra.{0}-{1}.convt'.format(n_extra, c_ntime))(x)\n",
    "        x = BatchNorm(gamma_initializer=gamma_init, epsilon=1.01e-5, momentum=0.9,\n",
    "                name='extra.{0}-{1}.bn'.format(n_extra, c_ntime))(x, training=1)\n",
    "        x = Activation(\"relu\",\n",
    "               name = 'extra.{0}-{1}.relu'.format(n_extra, c_ntime))(x)\n",
    "        c_ntime = c_ntime * 2\n",
    "        n_extra += 1\n",
    "        \n",
    "    x = Conv2DT(filters=n_c, kernel_size=ks, strides=strides, use_bias=False,\n",
    "            kernel_initializer=conv_init, padding='same', #kernel_regularizer=l2_reg,\n",
    "            name='final.{0}-{1}.convt'.format(c_ngf, n_c))(x)\n",
    "    outputs = Activation('tanh')(x)\n",
    "    \n",
    "#     if n_class is not None:\n",
    "#         return Model(inputs=[input_z, input_class], outputs=[outputs], name='generator')\n",
    "    \n",
    "    return Model(inputs=[input_z], outputs=[outputs], name='generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_sample(X, batch_size=32, y=None):\n",
    "    \n",
    "    idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "    X_true = X[idx, :]\n",
    "    \n",
    "    if y is not None:\n",
    "        y_true = y[idx]\n",
    "        return X_true, y_true\n",
    "    \n",
    "    return X_true\n",
    "\n",
    "        \n",
    "def next_batch(X, y, batch_size=32, shuffle=True):\n",
    "    \"\"\"\n",
    "    Get next batch data\n",
    "    \n",
    "    Inputs: \n",
    "    - X: input data\n",
    "    - y: input data label\n",
    "    - batch_size: s\n",
    "    \n",
    "    Outputs tuple of batch data \n",
    "    - X_batch: batch sampled X \n",
    "    - y_batch: batch sampled y\n",
    "    \"\"\"\n",
    "    \n",
    "    n_sample = X.shape[0]\n",
    "    n_batch = n_sample // batch_size\n",
    "    n_batch = n_batch + 1 if (n_sample % n_batch) != 0 else n_batch \n",
    "    idx = np.array(range(n_sample))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "    for b_idx in range(n_batch):\n",
    "        start, end = b_idx * batch_size, (b_idx + 1) * batch_size\n",
    "        if end >= n_sample:\n",
    "            sample_idx = idx[start:]\n",
    "        else:\n",
    "            sample_idx = idx[start:end] \n",
    "        \n",
    "        X_batch, y_batch = X[sample_idx, :], y[sample_idx, :]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "n_c = 2\n",
    "n_freq = 64\n",
    "n_time = 1024\n",
    "n_class = 2\n",
    "\n",
    "# GAN parameters\n",
    "n_z = 128\n",
    "n_gf = 64\n",
    "n_df = 64\n",
    "g_lambda = 10\n",
    "\n",
    "# optim parameters\n",
    "lrD = 1e-4\n",
    "lrG = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netD = MUSIC_DCGAN_D(n_freq, n_time, n_c, n_df)\n",
    "netD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = MUSIC_DCGAN_G(n_z, n_gf, n_freq, n_time, n_c)\n",
    "netG.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code is from https://github.com/tjwei/GANotebooks/blob/master/wgan-keras.ipynb\n",
    "\n",
    "netD_real_input = Input(shape=(n_freq, n_time, n_c))\n",
    "noisev = Input(shape=(n_z,))\n",
    "netD_fake_input = netG(noisev)\n",
    "\n",
    "e_input = K.placeholder(shape=(None,1,1,1))\n",
    "netD_mixed_input = Input(shape=(n_freq, n_time, n_c),\n",
    "    tensor=e_input * netD_real_input + (1 - e_input) * netD_fake_input)\n",
    "\n",
    "\n",
    "loss_real = K.mean(netD(netD_real_input))\n",
    "loss_fake = K.mean(netD(netD_fake_input))\n",
    "\n",
    "grad_mixed = K.gradients(netD(netD_mixed_input), [netD_mixed_input])[0]\n",
    "norm_grad_mixed = K.sqrt(K.sum(K.square(grad_mixed), axis=[1,2,3]))\n",
    "grad_penalty = K.mean(K.square(norm_grad_mixed -1))\n",
    "\n",
    "wgan_g_loss = loss_fake - loss_real + g_lambda * grad_penalty\n",
    "\n",
    "\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5, beta_2=0.9).get_updates(netD.trainable_weights,[], wgan_g_loss)\n",
    "netD_train = K.function([netD_real_input, noisev, e_input],\n",
    "                        [loss_real, loss_fake],    \n",
    "                        training_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan_d_loss = -loss_fake \n",
    "training_updates = Adam(lr=lrG, beta_1=0.5, beta_2=0.9).get_updates(netG.trainable_weights,[], wgan_d_loss)\n",
    "netG_train = K.function([noisev], [wgan_d_loss], training_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_audio_sample(X, y, batch_size, rand_slice=False):\n",
    "    \n",
    "#     #idx = np.random.choice(X.shape[0], batch_size)\n",
    "    \n",
    "#     X_batch = X\n",
    "#     y_batch = y\n",
    "    \n",
    "#     X_batch = audio_to_spec_64x1024(X_batch, rand_slice)\n",
    "    \n",
    "#     return X_batch, y_batch\n",
    "\n",
    "\n",
    "def audio_to_spec_64x1024(X, rand_slice=True):\n",
    "    \"\"\"\n",
    "    Sample audio to spectrum \n",
    "    \n",
    "    Sampled audio to 2 channel spectrum image\n",
    "    Seperate imag and real part as 2 channel image\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_fft = 128\n",
    "    n_pt = 64 * 1024\n",
    "    n_len = X.shape[1]\n",
    "    start = 0\n",
    "    if rand_slice:\n",
    "        start, = np.random.choice(n_len - n_pt, 1)\n",
    "    \n",
    "    X_slice = X[:, start:start+n_pt]\n",
    "    _, _, z = sp_stft(X_slice, nperseg=n_fft)\n",
    "    \n",
    "    z = z[:, :64, :1024]\n",
    "    z = z / np.max(np.abs(z), axis=(1, 2), keepdims=True)\n",
    "    z = np.expand_dims(z, -1)\n",
    "    z_real = np.real(z)\n",
    "    z_imag = np.imag(z)\n",
    "    z = np.concatenate([z_real, z_imag], axis=-1)\n",
    "    \n",
    "    return z\n",
    "\n",
    "def spec_to_audio(X):\n",
    "    \"\"\"\n",
    "    Convert 2 channel spectrum back to audio\n",
    "    \n",
    "    \"\"\"\n",
    "    xx = spec2ch_to_spec(X)\n",
    "    \n",
    "    _, recon = sp_istft(xx)\n",
    "    \n",
    "    return recon\n",
    "\n",
    "def spec2ch_to_spec(X):\n",
    "    \"\"\"\n",
    "    Covert 2 channel spectrum image to complex spectrum\n",
    "    \"\"\"\n",
    "    \n",
    "    xx = X[:, :, :, 0] + X[:, :, :, 1]*1j\n",
    "    \n",
    "    return xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load music data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/midi_2000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.vstack(X_train[:, 0]), X_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "base = 0\n",
    "epochs = 1000\n",
    "\n",
    "g_step = 0\n",
    "N_CRITICS = 5\n",
    "\n",
    "rand_slice = True\n",
    "\n",
    "fixed_noise = np.random.normal(0.0, 1.0, size=(batch_size, n_z))\n",
    "\n",
    "d_loss_hist = []\n",
    "g_loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "for epoch in np.arange(base, epochs):\n",
    "    \n",
    "    # shuffle data\n",
    "    idx = np.arange(len(X_train))\n",
    "    np.random.shuffle(idx)\n",
    "    X_train = X_train[idx]\n",
    "    y_train =  y_train[idx]\n",
    "    n_sample = X_train.shape[0]\n",
    "    n_batch = n_sample // batch_size\n",
    "    n_batch = n_batch + 1 if (n_sample % n_batch) != 0 else n_batch \n",
    "    \n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    \n",
    "    for n_b in range(n_batch):\n",
    "        start, end = n_b * batch_size, (n_b + 1) * batch_size\n",
    "        if end >= n_sample:\n",
    "            X_batch = X_train[start:]\n",
    "        else:\n",
    "            X_batch = X_train[start:end]\n",
    "    \n",
    "        n_critics = N_CRITICS\n",
    "        if g_step < 25 or g_step % 500 == 0:\n",
    "            n_critics = 100\n",
    "\n",
    "        ######################\n",
    "        # Train discriminator\n",
    "        ######################\n",
    "        for _ in range(n_critics):\n",
    "                \n",
    "            #y_batch = y[b_start:b_end]\n",
    "            #real_data = get_real_sample(X_train, half_batch)\n",
    "            real_data = audio_to_spec_64x1024(X_batch, rand_slice)\n",
    "\n",
    "            noise = np.random.normal(0.0, 1.0, size=(batch_size, n_z))   \n",
    "            e = np.random.uniform(size=(batch_size, 1, 1, 1))\n",
    "            err_real, err_fake  = netD_train([real_data, noise, e])\n",
    "\n",
    "            # paper suggest as index of wgan training the small the better\n",
    "            wgan_d_loss = err_real - err_fake\n",
    "        \n",
    "        ###################\n",
    "        # Train generator\n",
    "        ###################\n",
    "        noise = np.random.normal(0.0, 1.0, size=(batch_size, n_z))\n",
    "        wgan_g_loss, = netG_train([noise])\n",
    "\n",
    "        #if g_step % 20 == 0:\n",
    "        #    print('[{:3d}/{:3d}] [{:4d}/{:4d}] Time: {:.2f} D: {:.6f} G: {:.6f}'\n",
    "        #     .format(epoch, epochs, n_b, n_batch, time.time() - t0, \n",
    "        #             wgan_d_loss, wgan_g_loss))\n",
    "            \n",
    "        d_loss.append(wgan_d_loss)\n",
    "        g_loss.append(wgan_g_loss)\n",
    "        g_step += 1\n",
    "    \n",
    "    print('[{:3d}/{:3d}] Time: {:.2f} D: {:.6f} G: {:.6f}'\n",
    "        .format(epoch, epochs, time.time() - t0, \n",
    "                     wgan_d_loss, wgan_g_loss))\n",
    "         \n",
    "    d_loss_hist.append(np.mean(d_loss))\n",
    "    g_loss_hist.append(np.mean(g_loss))    \n",
    "    \n",
    "    print('Epochs {:d}'.format(epoch)) \n",
    "    print(\"Visualize STFT\")\n",
    "    gen = netG.predict(fixed_noise)\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.subplot(211)\n",
    "    specshow(librosa.power_to_db(np.abs(spec2ch_to_spec(gen)[0])))  \n",
    "    plt.subplot(212)\n",
    "    specshow(librosa.power_to_db(np.abs(spec2ch_to_spec(real_data)[0])))\n",
    "        \n",
    "        \n",
    "    print(\"Loss WGAN DIS {:.6f}\".format(np.mean(d_loss)))\n",
    "    print(\"Loss WGAN GEN {:.6f}\".format(np.mean(g_loss)))\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.xlim([0, epochs])\n",
    "    plt.plot(d_loss_hist, c='green', label='DISC')\n",
    "    plt.plot(g_loss_hist, c='red', label='GEN')\n",
    "    plt.legend()\n",
    "    plt.xlim([0, epochs])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        ipyd.clear_output()\n",
    "    \n",
    "    if epoch % 50 == 0: \n",
    "        netD.save('weights/netD_epoch_{:d}_v3.h5'.format(epoch))\n",
    "        netG.save('weights/netG_epoch_{:d}_v3.h5'.format(epoch))\n",
    "        \n",
    "        #np.save('weights/d_loss_hist_epoch_{:d}.npy'.format(epoch), np.array(d_loss_hist))\n",
    "        #np.save('weights/g_loss_hist_epoch_{:d}.npy'.format(epoch), np.array(g_loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final result\n",
    "np.save('weights/fixed_noise_seed.npy', fixed_noise)\n",
    "\n",
    "np.save('weights/d_loss_hist_epoch_{:d}.npy'.format(epochs), np.array(d_loss_hist))\n",
    "np.save('weights/g_loss_hist_epoch_{:d}.npy'.format(epochs), np.array(g_loss_hist))\n",
    "\n",
    "netD.save('weights/netD_epoch_{:d}_v3.h5'.format(epochs))\n",
    "netG.save('weights/netG_epoch_{:d}_v3.h5'.format(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = netG.predict(fixed_noise)\n",
    "gen_recon = spec_to_audio(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    print('Generate result {:d}'.format(i + 1))\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.subplot(211)\n",
    "    plt.title('STFT Linear-frequency power spectrogram')\n",
    "    specshow(librosa.power_to_db(np.abs(spec2ch_to_spec(gen)[i])), \n",
    "             hop_length=64, sr=2000,\n",
    "             y_axis='linear', x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt.title('WAV (mono)')\n",
    "    waveplot(gen_recon[i], sr=2000)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    ipyd.display(ipyd.Audio(gen_recon[i], rate=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.subplot(211)\n",
    "plt.title('STFT Linear-frequency power spectrogram')\n",
    "specshow(librosa.power_to_db(np.abs(spec2ch_to_spec(real_data)[i])), \n",
    "         hop_length=64, sr=2000,\n",
    "         y_axis='linear', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "    \n",
    "plt.subplot(212)\n",
    "plt.title('WAV (mono)')\n",
    "waveplot(real_recon[i], sr=2000)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "ipyd.display(ipyd.Audio(gen_recon[i], rate=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-CPU",
   "language": "python",
   "name": "dl-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
